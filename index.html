<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>DMC</title>
<link href="./DMC_files/style.css" rel="stylesheet">
<script type="text/javascript" src="./DMC_files/jquery.mlens-1.0.min.js"></script> 
<script type="text/javascript" src="./DMC_files/jquery.js"></script>
<script type="text/javascript" src="./DMC_files/video-comparison.js"></script>
<script type="module" src="https://ajax.googleapis.com/ajax/libs/model-viewer/3.0.1/model-viewer.min.js"></script>
<!-- <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script> -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-PWQ7C72CGK"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PWQ7C72CGK');
</script>

<meta charset="utf-8">
<!-- <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no"> -->
<meta name="viewport" content="width=1000; user-scalable=0;" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css">
<link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,500,600' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="/assets/css/Highlight-Clean.css">
<link rel="stylesheet" href="/assets/css/styles.css">

<link rel="apple-touch-icon" sizes="180x180" href="favicon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon.png">
<link rel="icon" type="image/png" href="favicon.png">
<link rel="manifest" href="/site.webmanifest">

<!--<meta property="og:site_name" content="DreamBooth3D: Subject driven Text-to-3D generation"/>-->
<!--<meta property="og:type" content="video.other" />-->
<!--<meta property="og:title" content="DreamBooth3D: Subject driven Text-to-3D generation" />-->
<!--<meta property="og:description" content="DreamBooth3D: Subject driven text-to-3D generation" />-->
<!--<meta property="og:url" content="https://dreambooth3d.github.io/" />-->

<!--<meta property="article:publisher" content="https://dreambooth3d.github.io/" />-->
<!--<meta name="twitter:card" content="summary_large_image" />-->
<!--<meta name="twitter:title" content="DreamBooth3D: Subject driven Text-to-3D generation" />-->
<!--<meta name="twitter:description" content="We combine DreamBooth and DreamFusion for subject driven text to 3D generation" />-->
<!--<meta name="twitter:url" content="https://dreambooth3d.github.io/" />-->
    <!-- <meta name="twitter:site" content="" /> -->



<style>
  * {
    box-sizing: border-box;
  }
  
  #video-compare-container {
	display: inline-block;
	line-height: 0;
	position: relative;
	width: 100%;
	padding-top: 42.3%;
}
#video-compare-container > video {
	width: 100%;
	position: absolute;
	top: 0;
	height: 100%;
}
#video-clipper {
	width: 50%;
	position: absolute;
	top: 0;
	bottom: 0;
	overflow: hidden;
}
#video-clipper video {
	width: 200%;
	position: absolute;
	height: 100%;
}
  .column {
    float: left;
    width: 20%;
    padding: 5px;
  }

  .colum4 {
    float: left;
    width: 25%;
    padding: 5px;
  }
  
  /* Clearfix (clear floats) */
  .row::after {
    content: "";
    clear: both;
    display: table;
  }
  </style>
 <style>
  .grid {
   display: flex;
   flex-direction: row;
   padding: 5px;
   align-content: center;
   /* flex-wrap: wrap; */
  }
  .grid > div {
   flex-grow: 1;
   flex-shrink: 1;
   padding: 5px;
   
  }
  .center {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 50%;
}
html {
  scroll-behavior: smooth;
}
  </style>
</head>

<body>
<div class="content">
  <h1><strong>DMC: Training-Free Video Diffusion Acceleration via Direction-Magnitude Cooperation</strong></h1>
  <br><br>
<!--      <font size="+2">-->
<!--          <p style="text-align: center;">-->
<!--            <a href="http://arxiv.org/abs/xxx" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;-->
<!--            <a href="#sum-video">[GitHub]</a> &nbsp;&nbsp;&nbsp;&nbsp;-->
<!--            <a href="#bib">[BibTeX]</a>-->
<!--          </p>-->
<!--    </font>-->
<!--  <img src="teaser_fig.gif" class="teaser-gif" style="width:100%;" loop=infinite><br>-->
<!--  <h2>Video Gallery</h2>-->
  <p>prompt1: XXXX.</p>
  <br>
  <div class="row">
    <div class="colum4">
      <video style="width: 100%" autoplay muted loop>
        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">
        </video>
      <p style="text-align: center;">Large</p>
    </div>
    <div class="colum4">
      <video style="width: 100%" autoplay muted loop>
        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">
        </video>
      <p style="text-align: center;">TeaCache</p>
    </div>
    <div class="colum4">
      <video style="width: 100%" autoplay muted loop>
        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">
        </video>
      <p style="text-align: center;">SRD</p>
    </div>
    <div class="colum4">
      <video style="width: 100%" autoplay muted loop>
        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">
        </video>
      <p style="text-align: center;">Ours</p>
    </div>
  </div>
  <br><br><br>
  <p>prompt2: XXXX.</p>
  <br>
  <div class="row">
    <div class="colum4">
      <video style="width: 100%" autoplay muted loop>
        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">
        </video>
      <p style="text-align: center;">Large</p>
    </div>
    <div class="colum4">
      <video style="width: 100%" autoplay muted loop>
        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">
        </video>
      <p style="text-align: center;">TeaCache</p>
    </div>
    <div class="colum4">
      <video style="width: 100%" autoplay muted loop>
        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">
        </video>
      <p style="text-align: center;">SRD</p>
    </div>
    <div class="colum4">
      <video style="width: 100%" autoplay muted loop>
        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">
        </video>
      <p style="text-align: center;">Ours</p>
    </div>
  </div>
</div>
<!--<div class="content">-->
<!--  <h2>Abstract</h2>-->
<!--  <p>Diffusion Transformer (DiT)-based video generation achieves impressive performance but suffers from high computational overhead.-->
<!--    Recently, the large-small model collaboration inference strategy has shown promise in accelerating inference.-->
<!--    However, the small model’s limited capacity can cause deviations from the large model’s denoising trajectory, resulting in suboptimal visual retention.-->
<!--    In this paper, through empirical analysis, we find that such deviations mainly stem from directional rather than magnitude discrepancies, and that reusing the large model’s prior directional information allows accurate directional estimation.-->
<!--    Building on this insight, we propose DMC, which leverages direction-magnitude collaboration to accelerate inference.-->
<!--    Specifically, we combine the complementary advantages of the small model’s accurate magnitude estimation with prior directional information to correct directional deviations.-->
<!--    Moreover, since the magnitude remains consistent under classifier-free guidance (CFG), the inference latency of the small model can be further halved by reusing the magnitude information.-->
<!--    As a result, DMC achieves the dual benefits of visual retention and reduced inference cost through calibrated lightweight small model inference.-->
<!--    Extensive experiments show that DMC outperforms existing acceleration methods, providing a 2.95X speedup on Wan2.1 while keeping video quality comparable to the baseline.</p>-->
<!--</div>-->

<!--<div class="content">-->
<!--  <h2>Video Gallery</h2>-->
<!--  <p>prompt1: XXXX.</p>-->
<!--  <br>-->
<!--  <div class="row">-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">-->
<!--        </video>-->
<!--      <p style="text-align: center;">Large</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">-->
<!--        </video>-->
<!--      <p style="text-align: center;">TeaCache</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">-->
<!--        </video>-->
<!--      <p style="text-align: center;">SRD</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">-->
<!--        </video>-->
<!--      <p style="text-align: center;">Ours</p>-->
<!--    </div>-->
<!--  </div>-->
<!--  <br><br><br>-->
<!--  <p>prompt2: XXXX.</p>-->
<!--  <br>-->
<!--  <div class="row">-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">-->
<!--        </video>-->
<!--      <p style="text-align: center;">Large</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">-->
<!--        </video>-->
<!--      <p style="text-align: center;">TeaCache</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">-->
<!--        </video>-->
<!--      <p style="text-align: center;">SRD</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4">-->
<!--        </video>-->
<!--      <p style="text-align: center;">Ours</p>-->
<!--    </div>-->
<!--  </div>-->

<!--</div>-->

<!--<div class="content">-->
<!--  <h2>Methodology</h2>-->
<!--  <p> In this study, we explore the relationship between the directional and magnitude components of-->
<!--model outputs across different-scale models within the same model family. Our empirical find- -->
<!--ings reveal that, for the denoising process of the same latent variable at the same time step: (1) in-->
<!--terms of direction, the large model’s output aligns more closely with that obtained through residual-->
<!--reuse, while deviating more noticeably from the small model’s output direction; and (2) in terms-->
<!--of magnitude, the large model’s output is comparable to that of the small model but deviates more-->
<!--substantially from the magnitude estimated via residual reuse. In short, the large model resembles-->
<!--the small model in output magnitude, yet aligns more closely with residual reuse in output direction.<br><br>-->
<!--    Building on these insights, we propose DMC, a novel method to accelerate diffusion inference-->
<!--through direction-magnitude cooperation. Specifically, DMC combines the strengths of small-model-->
<!--magnitude estimation with residual reuse from large-model for directional estimation. In this way,-->
<!--DMC refines the small model’s directional predictions to more closely align with those of the large-->
<!--model, while replacing the large model’s computationally intensive inference with a lightweight al- -->
<!--ternative. To prevent the accumulation of directional errors caused by residual reuse, DMC employs-->
<!--the small model as a proxy to monitor error growth continuously and adaptively switches to the large-->
<!--model when necessary, thereby ensuring timely directional correction. Moreover, the comparable-->
<!--magnitudes of conditional and unconditional predictions under CFG enable effective reuse, which-->
<!--can additionally reduce the small model’s inference cost by half. Extensive experiments demonstrate-->
<!--the effectiveness of DMC, showing that it can achieve higher acceleration rates while maintaining-->
<!--high visual retention.<br><br>-->
<!--    In summary, our contributions are as follows:<br><br>-->
<!--    1) We analyze the large-small model collaboration strategy and discover that directly replacing the-->
<!--large model’s predictions with those of the small model deviates from the original denoising tra- -->
<!--jectory, resulting in reduced visual retention.<br><br>-->
<!--    2) We empirically find that, within the same model family, small models can reliably estimate the-->
<!--magnitude of outputs from large models, while leveraging cached residuals from large models-->
<!--provides a robust approximation of output direction.<br><br>-->
<!--    3) We propose DMC, a training-free acceleration method that uses directional information from large-->
<!--model residual reuse to calibrate a small model’s predictions, improving its approximation of the-->
<!--large model while replacing costly inference. DMC also introduces CFG-Reuse, reducing the-->
<!--small model’s inference cost by half while maintaining performance.<br><br>-->
<!--    4) Extensive experiments across various video diffusion models demonstrate that our DMC out- -->
<!--performs the current state-of-the-art acceleration strategies, achieving significant speedup while-->
<!--maintaining faithful visual fidelity.-->
<!--  </p>-->
<!--  <br>-->
<!--&lt;!&ndash;  <img src="./DMC_files/Approach.png" style="width: 100%"> <br>&ndash;&gt;-->
<!--</div>-->



<!--<div class="content">-->
<!--  <h2>Material Change</h2>-->
<!--  <p>Our framework allows versatile 3D generation with simple modifications in the text prompts. -->
<!--    Here, we show some Material editing results. Notice that the glass sculpture and the statue of the dog correspond to the given subject.-->
<!--  </p>-->
<!--  <br>-->
<!--  <div class="row">-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/dog_cluster/Dog_cluster_8.png" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/vid_results/dog.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/vid_results/dog_glass.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/vid_results/dog_stone.gif" style="width:100%;"> -->
<!--    </div>-->
<!--  </div>-->

<!--  <div class="row">-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/dog_cluster/Dog_cluster_2.png" style="width:100%;"> -->
<!--      <p style="text-align: center;">Conditioning Images</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/vid_results/dog2.gif" style="width:100%;"> -->
<!--      <p style="text-align: center;">A photo of a dog</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/vid_results/dog2_glass.gif" style="width:100%;"> -->
<!--      <p style="text-align: center;">A dog made of glass</p>-->

<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/vid_results/dog2_stone.gif" style="width:100%;"> -->
<!--      <p style="text-align: center;">A stone statue of a dog</p>-->

<!--    </div>-->
<!--  </div>-->

<!--</div>-->

<!--<div class="content">-->
<!--  <h2>Qualitative Comparison</h2>-->
<!--  <p>Dreambooth 3D can introduce color changes in a consistent manner. We use a prompt of the following format : "A < color > backpack" for these results, -->
<!--    where the caption of each image represents the < color > .-->
<!--  </p>-->
<!--  <br>-->
<!--  <div class="row">-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/clusters/Img_clusters_bag.png" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_pink.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_green.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bag_grey.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--    </div>-->
<!--  </div>-->

<!--  <div class="row">-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/clusters/Img_Clusters_bagd.png" style="width:100%;"> -->
<!--      <p style="text-align: center;">Conditioning Images</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bagd_pink.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--        <p style="text-align: center;">"Pink"</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bagd_green.mp4" type="video/mp4"> -->
<!--        </video> -->
<!--        <p style="text-align: center;">"Green"</p>-->

<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/bagd_grey.mp4" type="video/mp4"> -->
<!--        </video> -->
<!--        <p style="text-align: center;">"Grey"</p>-->

<!--    </div>-->
<!--  </div>-->

<!--</div>-->

<!--<div class="content">-->
<!--  <h2>Pose Variations</h2>-->
<!--  <p>We can even perform non-rigid deformations such as pose changes relatively easily with simple modifications of text prompts.-->
<!--     Here we show different dog subject results in various poses. Note that none of the exemplar images contain an image of a jumping or sleeping dog.</p>-->
<!--  <br>-->
<!--  <div class="row">-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/dog_cluster/Dog_cluster_6.png" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/dog6.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/dog6_sleep.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/dog6_jump.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--    </div>-->
<!--  </div>-->

<!--  <div class="row">-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/dog_cluster/Dog_cluster_3.png" style="width:100%;"> -->
<!--      <p style="text-align: center;">Conditioning Images</p>-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/dog7.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--        <p style="text-align: center;">Photo of a dog sitting</p>-->

<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/dog7_sleep.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--        <p style="text-align: center;">Photo of a dog sleeping</p>-->

<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/dog7_jump.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--        <p style="text-align: center;">Photo of a dog jumping</p>-->

<!--    </div>-->
<!--  </div>-->

<!--</div>-->

<!--<div class="content">-->
<!--  <h2>Cartoon to 3D</h2>-->
<!--  <p> DreamBooth3D can even produce plausible 3D models from unrealistic cartoon images.</p>-->
<!--  <br>-->
<!--  <div class="row">-->
<!--    <div class="colum4">-->
<!--      &lt;!&ndash; <img src="./DMC_files/dog_cluster/Dog_cluster_8.png" style="width:100%;">  &ndash;&gt;-->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <img src="./DMC_files/clusters/cartoon.png" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="colum4">-->
<!--      <video style="width: 100%" autoplay muted loop>-->
<!--        <source src="./DMC_files/vid_results/cartoon_round.mp4" type="video/mp4"> -->
<!--        </video>-->
<!--    </div>-->
<!--  </div>-->

<!--</div>-->
<!--<div class="content">
  <h2>Text-Guided View Synthesis</h2>
  <p>Our technique can synthesized images with specified viewpoints for a subject cat (left to right: top, bottom, side and back views). Note that the generated poses are  different from the input poses, and the background changes in a realistic manner given a pose change. We also highlight the preservation of complex fur patterns on the subject cat's forehead.</p>
  <br>
  <img class="summary-img" src="./DMC_files/novel_views.png" style="width:100%;"> <br>
</div>
<div class="content">
  <h2>Property Modification</h2>
  <p>We show color modifications in the first row (using prompts ``a [color] [V] car''), and crosses between a specific dog and different animals in the second row (using prompts ``a cross of a [V] dog and a [target species]''). We highlight the fact that our method preserves unique visual features that give the subject its identity or essence, while performing the required property modification.</p>
  <br>
  <img class="summary-img" src="./DMC_files/property_modification.png" style="width:100%;"> <br>
</div>-->
<!--<div class="content">-->
<!--  <h2>Accessorization</h2>-->
<!--  <p>Our model can add accessories directly onto the 3D subject or into the scene, as in the rainbow carpet and green umbrella.-->
<!--  </p>-->
<!--  <br>-->
<!--  <div class="row">-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/dog_cluster/Dog_cluster_8.png" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/000.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/002.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/003.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/004.gif" style="width:100%;"> -->
<!--    </div>-->
<!--  </div>-->

<!--  <div class="row">-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/dog_cluster/Dog_cluster_1.png" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/006.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/008.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/009.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/010.gif" style="width:100%;"> -->
<!--    </div>-->
<!--  </div>-->

<!--  <div class="row">-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/dog_cluster/Dog_cluster_2.png" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/012.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/014.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/015.gif" style="width:100%;"> -->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/016.gif" style="width:100%;"> -->
<!--    </div>-->
<!--  </div>-->

<!--  <div class="row">-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/dog_cluster/Dog_cluster_3.png" style="width:100%;"> -->
<!--      <p style="text-align: center;">Conditioning Images</p>-->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/024.gif" style="width:100%;"> -->
<!--      <p style="text-align: center;">Photo of a dog</p>-->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/026.gif" style="width:100%;"> -->
<!--      <p style="text-align: center;">..sitting on a rainbow carpet</p>-->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/027.gif" style="width:100%;"> -->
<!--      <p style="text-align: center;">..sitting on a purple carpet</p>-->
<!--    </div>-->
<!--    <div class="column">-->
<!--      <img src="./DMC_files/gifs/028.gif" style="width:100%;"> -->
<!--      <p style="text-align: center;">..wearing a green umbrella</p>-->
<!--    </div>-->
<!--  </div>-->

<!--</div>-->
<!--<div class="content">-->
<!--  <h2>Mesh extraction</h2>-->
<!--  <p> Meshes can be extracted from the learnt volumetric representation using marching cube, which can then be used as a traditional mesh asset in different applications and for 3D printing.</p>-->
<!--  <div class="grid">-->
<!--    <div>-->
<!--      <img src="./DMC_files/dog_cluster/Dog_cluster_8.png" style="height:150px;"> -->
<!--      <p style="text-align: center;">Conditioning Images</p>-->
<!--    </div>-->
<!--    <div>-->
<!--      <img src="./DMC_files/gifs/005.gif" style="height:150px;">-->
<!--      <p style="text-align: center;">"Stone statue of a dog"</p>-->
<!--    </div>-->
<!--    <div>-->
<!--      <img src="./DMC_files/clusters/Img_Clusters_print.png" style="height:150px;"> -->
<!--      <p style="text-align: center;">3D printed asset</p>-->
<!--    </div>-->
<!--    <div>-->
<!--      <model-viewer src="DMC_files/dog_statue.glb" ar ar-modes="webxr scene-viewer quick-look" camera-controls shadow-intensity="1">-->
<!--      </model-viewer>-->
<!--      <p style="text-align: center;">Mesh</p>-->
<!--    </div>-->
<!--  </div>-->
<!--  <br>-->
<!--  -->
<!--</div>-->
<!--<div class="content">-->
<!--  <a id="sum-video"><h2>Summary</h2></a>-->
<!--  <br>-->
<!--  <iframe width="890" height="450" src="https://www.youtube.com/embed/kKVDrbfvOoA">-->
<!--  </iframe>-->
<!--   <br>-->
<!--</div>-->

<!--<div class="content">-->
<!--  <h2>Results with geometry</h2>-->
<!--  <p>Results for text based 3D asset generation conditioned on casual captures. The assets below are generated using the text prompt "A photograh of < object >". -->
<!--    Where < object > is the subject repesented in the exemplar images. The first column presents the exemplar images used to update our T2I model. -->
<!--    The second and third column shows two rendered views from the learnt volume. The last three columns shows the depth, normals and alpha maps for the second rendered view. </p>-->
<!--<img class="summary-img" src="./DMC_files/Dreambooth_geom.png" style="width:100%;">-->
<!--</div>-->
<!-- <div class="content">
  <h2>Societal Impact</h2>
  <p>This project aims to provide users with an effective tool for synthesizing personal subjects (animals, objects) in different contexts. While general text-to-image models might be biased towards specific attributes when synthesizing images from text, our approach enables the user to get a better reconstruction of their desirable subjects. On contrary, malicious parties might try to use such images to mislead viewers. This is a common issue, existing in other generative models approaches or content manipulation techniques. Future research in generative modeling, and specifically of personalized generative priors, must continue investigating and revalidating these concerns.</p>
  <br>
</div> -->
<!--<div class="content">-->
<!--  <a id="bib"><h2>BibTex</h2></a>-->
<!--  <code> @article{raj2023dreambooth3d,<br>-->
<!--  &nbsp;&nbsp;title={DreamBooth3D: Subject-Driven Text-to-3D Generation},<br>-->
<!--  &nbsp;&nbsp;author={Raj, Amit and Kaza, Srinivas and Poole, Ben and Niemeyer, Michael and Mildenhall,Ben and Ruiz, Nataniel and Zada, Shiran and Aberman, Kfir and Rubenstein, Michael and Barron, Jonathan and Li, Yuanzhen and Jampani, Varun},<br>-->
<!--  &nbsp;&nbsp;journal={ICCV},<br>-->
<!--  &nbsp;&nbsp;year={2023}<br>-->
<!--  } </code> -->
<!--</div>-->
<!-- <div class="content" id="acknowledgements">
  <p><strong>Acknowledgements</strong>:
  </p>
</div> -->
</body>
</html>
